import argparse
import concurrent.futures
import json
import os
import re
import sys
import time
from collections import OrderedDict
from datetime import datetime
from typing import Iterable, List, Tuple

# Allow importing sibling script check_word.py
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
if SCRIPT_DIR not in sys.path:
    sys.path.insert(0, SCRIPT_DIR)

from check_word import check_word_exists  # type: ignore


def read_file_text(path: str) -> str:
    with open(path, "r", encoding="utf-8") as f:
        return f.read()


def extract_words_from_ts(source_text: str) -> List[str]:
    """Extract quoted strings from a TS file that contains an array of words.

    This is resilient to formatting and will simply capture all quoted strings.
    The order is preserved and duplicates are removed later.
    """
    # Match both single and double quoted strings; handle escaped quotes
    pattern = re.compile(r"\"((?:\\.|[^\\\"])*)\"|'((?:\\.|[^\\'])*)'")
    words: List[str] = []
    for m in pattern.finditer(source_text):
        val = m.group(1) if m.group(1) is not None else m.group(2)
        if val is None:
            continue
        # Keep original Unicode as-is; do NOT decode with unicode_escape (avoids mojibake like 'รยก')
        # Minimal unescape of escaped quotes and backslashes inside TS strings
        val = val.replace('\\"', '"').replace("\\'", "'").replace('\\\\', '\\')
        val = val.strip()
        if val:
            words.append(val)
    return words


def dedupe_preserve_order(items: Iterable[str]) -> List[str]:
    seen = OrderedDict()
    for it in items:
        if it not in seen:
            seen[it] = None
    return list(seen.keys())


def check_words_bulk(words: List[str], concurrency: int = 5, delay_between_tasks: float = 0.0) -> Tuple[List[str], List[str]]:
    """Check words against ABL API with limited concurrency.

    Returns (existing_words, missing_words)
    """
    existing: List[str] = []
    missing: List[str] = []

    def task(word: str) -> Tuple[str, bool]:
        # Optional tiny delay to avoid bursting too quickly
        if delay_between_tasks:
            time.sleep(delay_between_tasks)
        try:
            result = check_word_exists(word)
            exists = bool(result and result.get("exists"))
            return word, exists
        except Exception:
            # Treat failures as missing; caller can re-run if needed
            return word, False

    with concurrent.futures.ThreadPoolExecutor(max_workers=concurrency) as executor:
        futures = [executor.submit(task, w) for w in words]
        for i, fut in enumerate(concurrent.futures.as_completed(futures), start=1):
            word, ok = fut.result()
            if ok:
                existing.append(word)
            else:
                missing.append(word)
            # Simple progress line
            print(f"[{i}/{len(words)}] {'OK' if ok else 'NO'} - {word}")

    return existing, missing


def write_ts_array(path: str, var_name: str, values: List[str]) -> None:
    os.makedirs(os.path.dirname(path), exist_ok=True)
    stamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    lines = []
    lines.append(f"// Auto-generated by scripts/filter_valid_words.py on {stamp}\n")
    lines.append(f"export const {var_name} = [\n")
    for v in values:
        # Two-space indent to align with existing style
        lines.append(f"  \"{v}\",\n")
    lines.append("] as const;\n")
    with open(path, "w", encoding="utf-8", newline="\n") as f:
        f.writelines(lines)


def main() -> int:
    parser = argparse.ArgumentParser(description="Filter words by existence in ABL API")
    parser.add_argument("input_ts", help="Path to src/lib/validWords.ts")
    parser.add_argument(
        "--out",
        dest="out_ts",
        default=os.path.join("src", "lib", "validWords_existing.ts"),
        help="Output TS file path (default: src/lib/validWords_existing.ts)",
    )
    parser.add_argument(
        "--var-name",
        dest="var_name",
        default="validWordsExisting",
        help="Exported TS variable name (default: validWordsExisting)",
    )
    parser.add_argument("--concurrency", type=int, default=5, help="Concurrent requests (default: 5)")
    parser.add_argument("--delay", type=float, default=0.05, help="Delay seconds between task submissions (default: 0.05)")
    parser.add_argument("--limit", type=int, default=0, help="Limit number of words for a dry run")
    args = parser.parse_args()

    src_text = read_file_text(args.input_ts)
    words = extract_words_from_ts(src_text)
    words = dedupe_preserve_order(words)
    if args.limit and args.limit > 0:
        words = words[: args.limit]

    print(f"Loaded {len(words)} unique words from {args.input_ts}")
    existing, missing = check_words_bulk(words, concurrency=max(1, args.concurrency), delay_between_tasks=max(0.0, args.delay))

    print(f"\nExisting: {len(existing)} | Missing: {len(missing)}")
    write_ts_array(args.out_ts, args.var_name, existing)
    print(f"Wrote filtered array to {args.out_ts} (var: {args.var_name})")
    return 0


if __name__ == "__main__":
    sys.exit(main())


